%
% Monografia de TCC1 de Douglas Brauner
%
\documentclass[twoside,english,brazilian]{UNISINOSmonografia}
\usepackage[utf8]{inputenc} % charset do texto (utf8, latin1, etc.)
\usepackage[T1]{fontenc} % encoding da fonte (afeta a sep. de sílabas)
\usepackage{graphicx} % comandos para gráficos e inclusão de figuras
\usepackage{bibentry} % para inserir refs. bib. no meio do texto
\usepackage{tabularx}
%=======================================================================
\unisinosbst

%=======================================================================
% Dados gerais sobre o trabalho.
%=======================================================================
\autor{Brauner}{Douglas}
\titulo{Elasticidade Baseada em Containers para Aplicação de Alto Desempenho}
%\subtitulo{sub}
\orientador[Prof.~Dr.]{Righi}{Rodrigo da Rosa}
%\coorientador[Prof.~Dr.]{Lamport}{Leslie}
\local{São Leopoldo}
\ano{2016}

\unidade{Unidade Acadêmica Graduação}
\curso{Curso de Bacharelado em Ciência da Computação}
\natureza{%
Trabalho de Conclusão de Curso apresentado como requisito parcial
para a obtenção do título de Bacharel em Ciência da Computação
pela Universidade do Vale do Rio dos Sinos --- UNISINOS
}

% cada palavra-chave deve ser fornecida duas vezes, uma em português e
% outra no idioma estrangeiro (na verdade, em tantos idiomas quantos se
% desejar).
% Se não fizer isto, não compila!
% TODO: adicionar mais palavras-chave
\palavrachave{brazilian}{Computação em Nuvem}
\palavrachave{brazilian}{Elasticidade}
\palavrachave{brazilian}{Containerização}
\palavrachave{english}{Cloud Computing}
\palavrachave{english}{Elasticity}
\palavrachave{english}{Containerization}
%palavrachave{}


%=======================================================================
% Início do documento.
%=======================================================================
\begin{document}
\capa
\folhaderosto
%\folhadeaprovacao % não deve ser incluída nos TCCs

%=======================================================================
% Dedicatória (opcional).
%
% O texto é normalmente colocado na parte de baixo da página, alinhado
% à direita.  Mas a formatação é basicamente livre.  Só não se escreve
% a palavra 'dedicatória'.
%=======================================================================
\begin{dedicatoria}
Aos nossos pais.\\[4ex] % quebra a linha dando um espaçamento maior
\begin{itshape} % faz o texto ficar em itálico
If I have seen farther than others,\\
it is because I stood on the shoulders of giants.\\
\end{itshape}
--- \textsc{Sir Isaac Newton} % \textsc é o "small caps"
\end{dedicatoria}

%=======================================================================
% Agradecimentos (opcional).
%=======================================================================
\begin{agradecimentos}
Obrigado!
\end{agradecimentos}

%=======================================================================
% Epígrafe (opcional).
%
% ``[...] o autor apresenta uma citação, seguida de indicação de autoria,
% relacionada com a matéria tratada no corpo do trabalho. Podem, também,
% constar epígrafes nas folhas de aberturas das seções primárias.''
%=======================================================================
\begin{epigrafe}
``\textit{Ninguém abre um livro sem que aprenda alguma coisa}''.\\
(Anônimo)
\end{epigrafe}

%=======================================================================
% Resumo em Português.
%
% A recomendação é para 150 a 500 palavras.
%=======================================================================
\begin{abstract}
A definir
\end{abstract}


\begin{otherlanguage}{english}
\begin{abstract}
A definir
\end{abstract}
\end{otherlanguage}

%=======================================================================
% Lista de Figuras (opcional).
%=======================================================================
%\listoffigures

%=======================================================================
% Lista de Tabelas (opcional).
%=======================================================================
%\listoftables

%=======================================================================
% Lista de Abreviaturas (opcional).
%
% Deve ser passada como parâmetro a maior das abreviaturas utilizadas.
%=======================================================================
%\begin{listadeabreviaturas}{seg., segs.}
%\item[ampl.] ampliado, -a
%\item[atual.] atualizado, -a
%\item[coord.] coordenador
%\item[N.~T.] Novo Testamento
%\item[seg., segs.] seguinte, -s
%\end{listadeabreviaturas}

%=======================================================================
% Lista de Siglas (opcional).
%
% Deve ser passada como parâmetro a maior das siglas utilizadas.
%=======================================================================
%\begin{listadesiglas}{FAPERGS}
%\item[ABNT] Associação Brasileira de Normas Técnicas
%\item[CAPES] Coordenação de Aperfeiçoamento de Pessoal de Nível Superior
%\item[FAPERGS] Fundação de Amparo à Pesquisa do Estado do Rio Grande do Sul
%\end{listadesiglas}

%=======================================================================
% Lista de Símbolos (opcional).
%
% Deve ser passado o maior (mais largo) dos símbolos utilizados.
%=======================================================================
%\begin{listadesimbolos}{Ca}
%\item[\textsuperscript{o}C] Graus Celsius
%\item[Al] Alumínio
%\item[Ca] Cálcio
%\end{listadesimbolos}

%=======================================================================
% Sumário
%=======================================================================
\tableofcontents

%=======================================================================
% Introdução
%=======================================================================
\chapter{Introdução}

% as epígrafes nos capítulos são opcionais

%\epigrafecap{The reasonable man adapts himself to the world; the unreasonable one persists in trying to adapt the world to himself. Therefore all progress depends on the unreasonable man.}{George Bernard Shaw}

%Conforme \citetexto{Hexsel11}, a introdução tem o objetivo de ``\emph{introduzir} o material que vai ser apresentado em mais detalhe nas seções subseqüentes''. Na introdução você deve contextualizar o problema e mostrar por que vale a pena resolvê-lo. Você deve apresentar a solução proposta e mostrar o seu diferencial em relação aos trabalhos relacionados. Observe, porém, que na introdução você deve apenas tratar do O QUÊ e PORQUÊ, sem tratar do como \cite{Hexsel11}, que deve ser explicado na seção que descreve o trabalho desenvolvido.


% Palavras-chave pesquisadas?
% docker virtual machine, container high performance computing, scalablity elasticity, hpc application container, virtualization containers.

No contexto de aplicações HPC iterativas, existem inúmeros casos de utilização, mas substancialmente o desempenho e isolamento são características necessárias para tais aplicações. \texit{Clusters} de HPC são apropriadamente utilizados para a execução destas aplicações, que são compartilhadas entre usuários de diferentes institutos, que utilizam os recursos para diferentes fins e diferentes requerimentos em questões de configuração de software e recursos. Dessa forma, tais plataformas se beneficiam de utilização de tecnologias de virtualização para fornecer ambientes customizados para as necesisadades e compartilhamento de recursos. Entretanto, aplicações de alto desempenho somente serão capazes de se beneficiar da utilização de ambientes virtualizados se não houver um overhead substancial de desempenho (CPU, memória, disco e rede) \cite{}. 
We presented container-based virtualization as an
lightweight alternative to hypervisors in HPC context. As we
have shown, there are useful usage cases in HPC where both
performance and isolation are need. In that way, we conducted
experiments to evaluate the current Linux containerbased
virtualization implementations and compare them to
Xen, a commonly used hypervisor-based implementation.
HPC clusters are typically shared among many users or
institutes, which may have different requirements in terms
of software packages and configurations. As presented, such
platforms might benefit from using virtualization technologies
to provide better resource sharing and custom environments.
However, HPC will only be able to take advantage
of virtualization systems if the fundamental performance
overhead (such as CPU, memory, disk and network) is
reduced. \cite{Xavier2013}

\section{Questão de Pesquisa}
Um dos grandes pontos a serem discutidos, no que diz respeito à implementação de um tratamento automático para a elasticidade, é a questão da análise do comportamento da aplicação. A qual oferece seus próprios obstáculos a serem transpostos. Uma técnica de auto-escalonamento que tenta antecipar os requisitos futuros de uma aplicação, baseado na análise de seu desempenho, é portanto, uma abordagem preditiva. Na literatura, este tema tem sido discutido sob diversos pontos de vista, como nos mostra o trabalho de \cite{Lorido-botr2012}. Algumas das técnicas sugeridas apresentam tanto uma natureza reativa quanto proativa, enquanto outras são excencialmente proativas. A análise preditiva baseada em séries temporais é identificada por \cite{Lorido-botr2012} como uma destas estratégias que têm uma abordagem puramente proativa. Uma série temporal é uma coleção de observações, as quais podem ser discretizadas ou não, feitas sequencialmente ao longo de um período de tempo. Ou como definido por \cite{Shumway2000}, séries temporais podem ser definidas como uma coleção de variáveis aleatórias indexadas de acordo com a ordem em que elas são obtidas no tempo. 


\begin{itemize}
	\item \textbf{Contexto e motivação:} 


	\item \textbf{Problema:}Considerando o cenário atual de aplicações HPC iterativas, bem como a elasticidade que containers oferecem, o trabalho aqui disposto busca responder a seguinte questão:
	\textit{Como seria o modelo de elasticidade em nuvem adaptado para o uso de containers para aplicações HPC iterativas, que possa gerar um ganho significativo de economia de recursos?} 
	\item \textbf{Objetivos:} 
	O objetivo geral deste trabalho é:
	\begin{itemize}
		\item Desenvolver um modelo de elasticidade automática adaptada para uso de containers, para aplicações de Computação de Alto Desempenho, em ambientes de computação em nuvem, com foco em otimizar a utilização de recursos, em comparação ao método de elasticidade automática baseado em virtualização de máquinas.  
	\end{itemize}
	Para atingir o objetivo acima citado, temos os seguintes objetivos secundários:
	\begin{itemize}
		\item Identificar as lacunas no estado da arte de computação em nuvem, em relação à estratégias de instanciação de recursos virtuais;
		\item Desenvolver uma estratégia de comparação com o \textit{estado da arte} de elasticidade, utilizando VMs;
		\item Desenvolver uma aplicação iterativa de alto desempenho para execução e simulação em nuvem;
		\item Realizar testes em laboratório, utilizando a aplicação desenvolvida e confrontando modelo de estado da arte e modelo proposto;
		\item Desenvolver melhoria para o algoritmo de instantiação de recursos para melhor uso de containers.
	\end{itemize}
\end{itemize}

%var/lib/one/ apps

% sunstone-server start
%=======================================================================
% Fundamentação Teórica
%=======================================================================
\chapter{Fundamentação Teórica}

\section{Computação em Nuvem}
Segundo a definição do National Institute of Standards and Technologies (NIST) \cite{Mell2012}, a computação em nuvem é um modelo que permite o acesso de recursos computacionais configuráveis e compartilhados, de forma conveniente, ubíqua e sob demanda, capazes de ser provisionados e entregues com baixo custo de gerenciamento e sem a intervenção de um provedor de serviços. Tais recursos podem ser: redes, servidores, serviços, armazenamento, aplicações, etc. Tais recursos são tipicamente fornecidos no modelo \textit{pay-as-you-go}, ou seja, você paga de acordo com a demanda de recursos solicitada \cite{Suleiman2012}. Sendo assim, a computação em nuvem se utiliza de mecanismos para escalar estes recursos conforme necessidade, através de algoritmos que irão trabalhar no balanceamento de carga rapidamente para diminuir o desperdício de recursos computacionais.
Algumas abordagens deixam o gerenciamento de balanceamento de carga e recursos por conta da aplicação, que se faz uso de API (\textit{Application Program Interface}) para definir por meio de codificação dentro da própria implementação o controle. Esta abordagen requer que a implementação tenha consciência dos pontos específicos de implementação do controle, o que pode fugir do foco principal do programa. Outras tecnologias oferecem um mecanismo externo à aplicação para o controle de recursos utilizados, deixando para a aplicação apenas determinar os pontos de chamada de sistema para reorganizações necessárias na topologia de comunicação. 
Podemos resumir a computação em nuvem para cinco características essenciais, além de três modelos de serviço e quatro modelos de implantação, conforme descritos em seguida \cite{Verdi2010}.

\subsection{Características essenciais}
As características dizem respeito ao que é necessário para uma abordagem ser considerada computação em nuvem. Estas vantagens, por assim dizer, são a clara distinção com outros paradigma, algumas características básicas para identificar uma solução de computação em nuvem são a elasticidade rápida dos recursos, medição de serviço e o amplo acesso \cite{Moreira2010}.
\begin{itemize}
	\item Serviço sob-demanda: as funcionalidades computacionais são providas automaticamente sem a interação humana com o provedor do serviço;
	\item Amplo acesso aos serviços: os recursos computacionais estão disponíveis através da Internet e são acessados via mecanismos padronizados, permitindo a utilização por diferentes plataformas de cliente e também por uma ampla gama de dispositivos;
	\item Pool de recursos: Os recursos computacionais do provedor (físicos ou virtuais) são utilizados para servir a múltiplos usuários, sendo alocados e realocados dinamicamente conforme a demanda \cite{verascloud};
	\item Elasticidade: Os recursos devem ser fornecidos de forma rápida e elástica, da mesma forma, devem ser liberados de forma eficiente. Essa alocação de recursos deve ser transparente ao usuário, além de dar a impressão que podem ser alocados proporcionamente conforme a demanda, sendo fornecidos a qualquer momento. Essa funcionalidade pode ser fornecida automaticamente ou mediante configuração prévia de \textit{scripts}.
	\item Medição de serviços: Os sistemas de gerenciamento utilizados em computação em nuvem devem ser capazes de monitorar e gerenciar de forma automatica os recursos para cada tipo de serviço (consumo de banda, operações de escrita e leitura, processamento de CPU, etc.). Da mesma forma que a elasticidade, essa funcionalidade deve ser transparente para o provedor de serviços, bem como para o consumidor desse serviço \cite{verascloud}.
\end{itemize}
A transparência no serviço disponibizado através de computação em nuvem é fundamental, já que o consumidor irá pagar pelo uso de recursos, e não mais pelo equipamento, como no modelo tradicional. Portanto, é imprescindível que esteja tudo bem claro para o consumidor poder pagar por aquilo que solicitou e não haver desperdícios desses recursos, que poderiam ser utilizados por outros consumidores.

\subsection{Modelos de serviços}
Existem três principais modelos de serviço para computação em nuvem. Estes modelos definem um padrão de arquitetura, bem como uma estruturação hierárquica, as mais diversas soluções de computação em nuvem podem ser identificadas como camadas nesses modelos. 
em nuvem. A Figura~\ref{fig:saas_paas} ilustra modelos de serviços.

\begin{figure}
	\caption{Modelos de serviço}
	\label{fig:saas_paas}
	\centering%
	\begin{minipage}{.4\textwidth}
		\includegraphics[width=\textwidth]{saas_paas}
		\fonte{\citetexto{Moreira2010}}
	\end{minipage}
\end{figure}
\begin{itemize}
	\item Software como um serviço (Software as a Service - SaaS): Para \citetexto{Mell2012}, é o modelo em que é fornecida ao consumidor a capacidade de utilizar os aplicativos disponibilizados pelo provedor através da Internet. O consumidor não gerencia nem controla a infraestrutura básica, incluindo rede, servidores e sistemas operacionais, nem mesmo as configurações de nenhum aplicativo, tendo a possibilidade de configurar apenas alguns aspectos restritos. Com esse modelo de serviço surge o termo multi-inquilino, no qual os usuários compartilham dos mesmos recursos disponibilizados pelo provedor, porém de forma isolada, ou seja, um não tem conhecimento do outro.
	\item Plataforma como um Serviço (Plataform as a Service - PaaS): Neste modelo de serviço, é fornecido ao usuário a possiblidade de desenvolver e extender aplicações e disponibilizar essas aplicações no serviço de computação em nuvem. O provedor do serviço disponibiliza a infrasestrutura e define uma série de ferramentas, bibliotecas e linguagens suportadas para o usuário. O controle da infrasestrutura é todo gerenciado pelo provedor, ficando o consumidor responsável apenas pela aplicação entregue \cite{Mell2012,verascloud}. Alguns exemplos deste modelo são Amazon Web Services \citetexto{AWS} e SAP Hana Cloud Platform \citetexto{SAPHCP}. 
	\item Infraestrutura como um Serviço (Infraestructure as a Service - IaaS): De acordo com \citetexto{Bhardwaj2010}, é a entrega de capacidade de hardware (rede, armazenamento e servidor), e programas associados (virtualização de sistemas operacionais, sistema de arquivos) como um serviço. Diferentemente do modelo tradicional de hospedagem, é permitido que o usuário aloque os recursos necessários de acordo com a demanda, ao invés de um contrato prévio. O controle que o provedor de IaaS possui é bem menor em comparação ao PaaS, por exemplo. Este se limita a apenas manter o \textit{data center} disponível e operacional o máximo possível. O usuário irá gerir seus softwares e aplicações como se estivesse em sua própria infrasestrutura. Alguns exemplos são Amazon Web Services Elastic Compute Cloud (EC2) e Secure Storage Service (S3) \cite{AWS}.
\end{itemize}
\subsection{Modelos de implantação}
Os modelos de implantação definem como se dará o acesso e diponibilidade da computação em nuvem para o usuário. A diferença entre os modelos se dão de acordo com o tipo de informação e processo de negócio, de acordo com necessidade.  Em alguns casos, por exemplo, não é aceitável para uma empresa ou governo que o \textit{data center} esteja localizado em um outro país. De acordo com \citetexto{Mell2012}, os modelos de implantação podem ser dividos da seguinte maneira:
\begin{itemize}
	\item Nuvem privada (private cloud): A infraestrutura utilizada para computação em nuvem é fornecida exclusivamente para uma única organização, sendo impedido o uso de recursos por qualquer usuário não autorizado pela organização. Neste caso, esta nuvem pode ser administrada por um provedor de serviço em nuvem ou até mesmo pela própria organização.
	\item Nuvem comunidade (community cloud): A infraestrutura é compartilhada por diversas organizações, sendo suportada por uma comunidade com interesses em comum. O gerenciamento dos recursos pode ser feito tanto pelas organizações em questão, quanto por um terceiro (provedor do serviço).
	\item Nuvem pública (public cloud): Este modelo permite que qualquer usuário possa fazer uso dos recursos, desde que conheça a localização do serviço e seja autorizado, normalmente pelo modelo \textit{pay-as-you-go}. Estes modelos são tipicamente oferecidos por grandes organizações que possui uma enorme capacidade de armazenamento e processamento.
	\item Nuvem hibrida (hybrid cloud): Neste modelo, a infraestrutura é composta por dois ou mais modelos de implantação de computação em nuvem (pública, privada, comunitária). Estas infraestruturas são conectadas através de um meio de comunicação, porém, continuando a ser entidades únicas.
\end{itemize}

% TODO: Diferenciar elasticidade e escalabilidade
\section{Elasticidade vs Escalabilidade}

A escalabilidade de uma aplicação se diz respeito à quantidade de usuários que ela pode manter conectados ao mesmo tempo, sendo o limite de escalabidade o ponto em que esta não pode suportar mais usuários conectados sem apresentar a mesma  eficiência \cite{Wilder12}. Uma aplicação pode ter a sua escalabilidade estendida através do fornecimento de recursos de \textit{hardware} adicionais, como memória, CPU, largura de banda, etc. No contexto de uma aplicação HPC, uma escalabilidade não se detêm apenas ao número de usuários suportados, mas também ao tipo de processamento que a aplicação precisa executar e que pode precisar de recursos adicionais para continuar desempenhando de forma efetiva. Dessa forma, um sistema é dito escalável quando seu desempenho não se degrada significantemente com o aumento dos usuários ou carga.
Segundo \citetexto{Taurion2012}, elasticidade é a capacidade do ambiente computacional da nuvem aumentar ou diminuir de forma automática os recursos computacionais demandados e provisionados para cada usuário. É a escalabilidade em duas direções: tanto cresce quanto diminui a capacidade ofertada. Os dois termos podem ser confundidos, já que dizem respeito à adaptação de recursos conforme demanda, porém a escalabilidade é relativa à capacidade manter o desempenho conforme a demanda, já a elasticidade é a capacidade de fazer os recursos se adpatem à carga, seja para aumentar ou diminuir. 
Iremos adotar a definição de \citetexto{coutinho2013elasticidade} que diz que a elasticidade é a ``Capacidade de adicionar e remover recursos de forma automática de acordo com a carga de trabalho sem interrupções e utilizando os recursos de forma otimizada.``.

\section{Docker}
O Docker, apesar de inicialmente utilizar o LXC como provedor de runtime, criou uma implementação própria de ferramenta para criação de containers, procurando resolver algumas limitações da implementação de LXC, como segurança e simplificação [ref].
Alguns dos termos chave para compreender a tecnologia são descritos abaixo \cite{whitepaperDocker2016}:  

\begin{itemize}
	\item Dockerfile - Um arquivo que contém os detalhes de configuração da aplicação, bem como os recursos que esta irá precisar, dizendo ao construtor da imagem como ela deve se parecer.
	\item Docker Image - Este é o resultado do dockerfile, uma imagem que contém um \textit{snapshot} da aplicação. O armazenamento e gerenciamento é feito no \textit{Docker registry}.
	\item Docker Container - A unidade isolada, na qual a aplicação é empacotada, juntamente com todas as bibliotecas e recursos necessários para execução. Em tempo de \textit{runtime} a engine faz a leitura de  uma image e carrega um container.
	\item Docker Engine - A runtime dos containers Docker, com recursos embutidos como: orquestração de containers, rede  e segurança que é instalado no host, seja virtual (VM) ou cloud (AWS, Azure, Google Cloud Enterprise etc).
	\item Docker Registry - Um serviço no qual são armazenadas as imagens Docker, além de serem protegidas e gerenciadas. No Docker registry é possível armazenar múltiplas versões de uma imagem (aplicação), através do uso de \textit{tags}. Com isto, é possível fazer uma atualização de uma imagem facilmente, através de uma modificação na imagem e armazená-la com uma versão diferente, sem comprometer a versão estável.
\end{itemize} 

\subsection{Containers}

A palavra \textit{container} ficou popularizada a partir de uma técnica de isolamento de recursos dentro de um sistema operacional baseado em UNIX, desde a release do sistema operacional Solaris 10 em 2005. A ideia era não somente restringir o acesso de recursos dentro deste container, mas também permitir uma proteção de recursos explicitamente dedicados à estes containers. Embora seja considerada como uma \textit{best practice} em desenvolvimento, a utilização de containers é bastante complexa e o mal uso pode levar à criação de aplicações com brechas de segurança, embora se pressuponha o contrário, diferente da facilidade que se tem com a utilização de máquinas virtuais (VM). Uma das implementações atuais de containers é o Linux Containers (LXC), que provê uma série de ferramentas que trabalham nativamente em sistemas operacionais baseado em UNIX para fornecer um ambiente semelhante ao que se obtêm com VM's, mas sem a sobrecarga de rodar um kernel separado e fazer simulação de hardware, através de utilização de namespaces, e \textit{control groups} \cite{LXC2016}.
Recentemente, a utilização de containers se popularizou em meio ao desenvolvimento de computação para a nuvem por causa da nova ferramenta chamada \textit{Docker}, criada em 2013 e inicialmente baseada no LXC como um provedor de runtime. Segundo \cite{NICKOLOFF2016}, Docker é um conjunto de ferramentas e serviço que facilitam a criação e manipulação de containers dentro de um sistema baseado em UNIX. Com Docker, é possível ter todas as vantagens de utilização de containers, porém sem o alto custo de configuração e com containers fornecidos seguindo as melhores práticas. 

\subsection{cgroups}
Cgroups é uma configuração que faz parte do subsistema de kernel de sistemas baseado em UNIX, que fornece controle sobre recursos do sistema, como CPU, memória, rede, etc. O cgroups, ou control groups esta presente na implementação de containers de Docker e é utilizado como mecanismo base de gerenciamemnto de recursos \cite{NICKOLOFF2016}.

\subsection{chroot}
Chroot (\textit{change root}) é um comando Linux para mudar o diretório root do processo corrente e seus processos aninhados para um novo diretório. Alguns containers utilizam este comando para isolar e compartilhar o sistema de arquivos entre os ambientes containerizados \cite{Dua2014}. 

\section{Virtualização vs Containerização}

Uma camada de virtualização pode ajudar a isolar um ambiente compartilhado de computadores. Em clusters de HPC, normalmente os recursos são compartilhados entre mais usuários e isto faz com que possa ocorrer problemas nesse compartilhamento \cite{Xavier2013}.
A camada de virtualização baseada em container possui uma performance muito superior à virtualização pura, segundo a pesquisa deles.


% Substituir o uso de VM no autoelastic e fazer testes de viabilidade de containers no lugar
% verificar vantagens e novas oportunidades que o autoelastic pode ter com containers.
% Fazer um comparativo - Docker vale a pena?
% Talvez modificar o formato de balanceamento de carga, já que containers podem ter menor custo.

\subsection{Virtualização baseada em Hypervisor}
Um \textit{hypervisor}, ou gerenciador de máquinas virtuais, é um programa que roda no sistema operacional host, fornecendo os recursos de hardware deste para uma série de máquinas virtuais, neste caso, estas máquinas virtuais compartilham o mesmo hardware. Como mostrado na figura~\ref{fig:vmvsdocker}, o hypervisor é responsável por fornecer o acesso aos recursos para cada sistema operacional dentro das máquinas virtuais, mas com o custo deste gerenciamento como processamento, já que a ferramenta procura fornecer comportamento fiel de hardware para as máquinas virtuais \cite{Zhang2016}.

\subsection{Virtualização baseada em container}

O termo \textit{containerização} é a forma popular para se referenciar à virtualização baseada em container, que permite o isolamento de determinados softwares, que são executados dentro do mesmo kernel no sistema operacional Linux, mas que diferentemente do hypervisor, não adiciona uma camada virtualização, na qual precisaria carregar um sistema operacional convidado \cite{Zhang2016}, como mostra a figura~\ref{fig:vmvsdocker}.
\cite{Dua2014}

A Figura~\ref{fig:vmvsdocker} ilustra a diferença entre uma aplicação em uma camada de virtualização por Docker e VM.

\begin{figure}
	\caption{Docker vs Virtual Machine}
	\label{fig:vmvsdocker}
	\centering%
	\begin{minipage}{.4\textwidth}
		\includegraphics[width=\textwidth]{vmvsdocker}
		\fonte{\citetexto{Cham12}}
	\end{minipage}
\end{figure}

\begin{table}[!ht]
	\caption{Características de VM e Containers}
	\label{tab:table1}
	\centering%
	\begin{center}
		\begin{tabularx}{.8\textwidth}{|X|X|X|}
			\hline
			\textbf{Parametro} &\textbf{Máquinas Virtuais}\ &\textbf{Containers}\\
			\hline
			SO Convidado &Um hardware virtual é disponibilizado para cada VM, com um espaço de memória reservado. & Todos os convidados compartilham o mesmo SO, cada imagem é carregada para o espaço de memória do Kernel\\
			Comunicação & Feita por dispositivos Ethernet & Utilização de mecanismos IPC como sinais, sockets, pipes\\
			Segurança & Depende da implementação do fornecedor de Hypervisor & Utilização de mecanismos de controle de acesso\\
			Desempenho & Irá receber uma sobrecarga pelo trabalho de tradução de instruções do sistema hospedeiro para o convidado & Containers fornecem um desempenho muito próximo ao nativo em comparação ao executado direto no hospedeiro\\
			Isolamento & Não é possível compartilhar arquivos, bibliotecas e execução de programas entre as máquinas virtuais & Subdiretórios podem ser montados e compartilhados entre containers no mesmo hospedeiro\\
			Tempo de início & Demora o tempo de processo de boot de um sistema operacional & Containers não fazem boot de sistema\\
			Armazenamento & Software específicos de armazenamento e sistema de arquivos precisam ser instalados no convidado além de estarem no hospedeiro & O armazenamento em containers pode ser compartilhado com o hospedeiro\\
			\hline
		\end{tabularx}
		\fonte{\cite{Dua2014}}
	\end{center}
\end{table}

\chapter{Trabalhos Relacionados}
Neste capítulo iremos ver um estudo de diversos trabalhos, os quais trazem soluções para elasticidade para aplicações de alto desempenho, bem como estudos comparativos entre a utilização de máquinas virtuais e containers. Serão apresentados os detalhes cada trabalho no início, e ao término do capítulo será feito uma comparação entre as abordagens.

\section{AutoElastic}

Segundo a definição de \citetext{Facco2016} para a ferramenta AutoElastic:
\begin{quote}
AutoElastic age como um \textit{middleware} permitindo que aplicações HPC iterativas obtenham vantagem do provisionamento de recursos dinâmico de uma infraestrutura de nuvem sem a necessidade de modificações no código fonte. AutoElastic oferece a elasticidade de forma automática, não sendo necessária a configuração de regras por parte do usuário.
\end{quote} 
O problema apresentado pelo trabalho é que muitas das abordagens atuais do mercado, para fornecer elasticidade em aplicações HPC, necessitam de uma intervenção do usuário para fazer tais configurações de elasticidade, ou seja, definir o momento em que serão adicionados ou removidos recursos, através de manipulação de máquinas virtuals, disponíveis para a aplicação, seja por uma configuração estática de \textit{threshold} ou de uma configuração no código da aplicação. O desenvolvimento do \textit{middleware} AutoElastic permite um modelo transparente ao usuário em questão de configuração de parâmetros. O AutoElastic possui um protótipo executado pelo autor na plataforma de nuvem OpenNebula e obteve resultados de ganho de desempenho de até 59\% na execução de uma aplicação de integração numérica \textit{CPU-Bound}, quando comparada com outras soluções de elasticidade. 

\section{Utilizando Docker para Aplicações de Alto Desempenho}
A definir

\section{Virtualization vs Containerization to support PaaS}
% O texto possui uma tabela de comparação das tecnologias, bem como de relação de PaaS com containers.
% Não se aprofunda muito na questão de comparação, mas pode ser extendido.
\cite{Dua2014} Apresenta um estudo sobre como provedores de PaaS estão utilizando containers para encapsular aplicações. O estudo endaga a atual adoção de plataformas baseadas em containers e explora diversas implementações de containers, entre elas: Linux Containers, Docker, Warden Container, lmctfy e OpenVZ. A análise foi feita baesada em como cada uma das tecnologias lidam com processos, sistema de arquivos e isolamento de namespaces, dando uma atenção especial à características únicas de cada implementação. Por fim, o trabalho busca fazer uma análise dos fatores que afetam a adoção de containers e possíveis funcionalidades que estão em falta para uma nova geração de PaaS.

De acordo com os autores, containers possuem uma vantagem inerente sobre máquinas virtuais, devido à melhorias de performance e redução de tempo de \textit{start up}. Apesar de existirem diversas soluções de containers no mercado, cada uma com prós e contras, eles tendem a manter um padrão, principalmente em relação ao uso de \textit{chroot} e \textit{namespaces}. Ressalta-se que Docker aplica camadas adicionais em cima da solução nativa Linux Containers, tornando a solução muito mais interoperável e mais interessante para provedores que não querem ficar presos à arquiteturas específicas. Já a solução OpenVZ se mostrou melhor em termos de segurança, porém isto associado ao custo de se ter um kernel customizado para a aplicação.

\section{Performance Evaluation of Container-based Virtualization for High Performance Computing Environments}
% Este estudo possui gráficos de comparação, porém o container está no nível IaaS, um pouco diferente do que preciso.
\cite{Xavier2013} Inicia o seu estudo abordando a utilização de tecnologias de virtualização para aplicações de alto desempenho, alegando que tais tecnologias foram tradicionalmente evitadas ao longo dos anos por sua adição de camadas que comprometem desempenho, o que é crucial para tais aplicações. Porém, como o advento de implementações de virtualização baseada em containers, o autor indaga que é possível se obter uma sobrecarga muito pequena com a utilização de tecnologias como Linux VServer, OpenVZ e Linux Containers (LXC), chegando a um desempenho quase nativo. Para embasar o questionamento, foi feito um comparativo de desempenho utilizando tais tecnologias e um modelo tradicional de virtualização, o Xen. 

Os experimentos feitos pelo autor utilizaram programas de avaliação de desempenho de supercomputadores fornecidos pela NASA \cite{NASA2016}. Os programas executados possuem diferentes focos de estressamento da aplicação, permitindo identificar o compartamento das implementações sob os mais diversos cenários. A partir da análise, se viu que os sistemas baseado em containers possuem uma performance muito próxima da nativa, tanto para CPU, memória, disco e rede, ficando a principal diferença na implementação de gerenciamento de recursos, no caso de  LXC, por exemplo, isolamento e segurança é garantido apenas por uso de \textit{cgroups}. O estudo critica o desempenho das implementações para isolamento de memória, disco e rede, mas considera um sucesso o isolamento de CPU. Apesar do provisionamento de recursos não estar completamente maduro para estas soluções, é importante perceber que para aplicações de alto desempenho, muitas vezes a CPU é o mais importante, além disto, essas aplicações normalmente não exigem a alocação compartilhada de partição do cluster para multiplos usuários ao mesmo tempo. Por fim, a implementação LXC foi considerada a melhor alternativa para substituir o modelo tradicional de virtualização em apliações HPC, se for considerado apenas o quesito CPU, no comparativo, a implementação obteve um desempenho muito próximo ao nativo, ou seja, o container executou os programas de teste com praticamente o mesmo potencial que a própria máquina, enquanto a implementação utilizando máquina virtual (XEN) obteve uma sobrecarga de aproximadamente 4.3\%.


\section{Comparativo dos trabalhos relacionados}

%Melhorar
Concluo que o aproveitamento máximo de recursos, utilizando uma camada de virtualização de fácil implementação e não muito dependente do sistema operacional é objetivo de um ambiente próprio para execução de aplicações de alto desempenho. Portanto, os trabalhos analisados deixaram uma lacuna em relação a esta questão por não apresentarem uma solução que utilize uma tecnologia mais eficiente para processamento do que máquinas virtuais para alocação de recursos em aplicações de alto desempenho. Alguns trabalhos abordaram o uso de containers para aplicações de alto desempenho, porém apenas executando programas de testes para comprovar a possibilidade de uso, sem aplicar em infraestrutura que possa fornecer os recursos para as aplicações. O objetivo do trabalho que traz o AutoElastic de \citetexto{Facco2016}, juntamente com a possibilidade de se otimizar a utilização de recursos utilizando containers é o que justificou a abordagem tomada por este presente trabalho.


\section{Questões de projeto}
Objetivo deste trabalho é propor uma melhoria para o modelo de elasticidade em nuvem para aplicações HPC iterativas (AutoElastic). A partir da substituição do componente de criação de recursos com a criação de máquinas virtuais por containers, espera-se atingir uma melhoria no tempo de espera para se ter os recursos computacionais disponíveis após a requisição. Com os resultados, será analisado em que situações os containers tem um desempenho melhor, podendo propor uma abordagem diferente de ação quando se atinge os \textit{thresholds}, fazendo o melhor uso da tecnologia. Portanto, o modelo proposto tem como escopo somente trabalhar nos recursos computacionais fornecidos para o modelo AutoElastic. 

%TODO
Desenvolver um modelo de elasticidade automática adaptada para uso de containers, para aplicações de Computação de Alto Desempenho, em ambientes de computação em nuvem, com foco em otimizar a utilização de recursos, em comparação ao método de elasticidade automática baseado em virtualização de máquinas.

No início deste trabalho propusemos a seguinte questão de pesquisa: a análise de séries temporais pode ser usada para encontrar padrões na carga de trabalho de uma aplicação, com o intuito de prever valores futuros, de forma que ofereça subsídios para a implementação de uma solução de elasticidade proativa? Neste ponto de nossos estudos, podemos afirmar com certeza que sim. Mas descobrimos que a pergunta pode e deve ser ampliada, para sabermos se é possível o uso de análise de séries temporais, utilizando-se de um modelo probabilístico que apresente alto grau de exatidão em suas predições e que tenha um bom desempenho, o qual nos permita utilizá-lo em tempo de execução sem um aumento acentuado de overhead.

Para que se possa manter o foco no real propósito deste trabalho, iremos abstrair as questões que permeiam a proposta e não são inerentemente fundamentais para a construção do módulo de predição. Sendo assim, como resultado deste modelo não teremos uma implementação genérica ou adaptável, ou ao menos esta não será uma preocupação de projeto, visto que os objetivos principais são o tempo de processamento e exatidão dos resultados. O escalonamento empregado será vertical e a única dimensão analisada o poder de processamento, pois estes itens são suficientes para que cumpramos os objetivos a que nos propusemos no início deste trabalho. 

Não será criada uma API detalhada neste momento. E até mesmo os resultados da predição não receberão um tratamento para serem consumidos por uma ou outra plataforma específica. Pois entendemos que estas são questões secundárias, e não influenciam no propósito principal do trabalho. Optando assim por manter baixa a complexidade do projeto. E de igual forma, usaremos uma plataforma de cloud arbitrária que julgarmos mais apropriada para a coleta dos dados, sem preocupação com compatibilidade com outras pelos mesmos motivos já descritos nesta seção.

\section{Arquitetura}

Tal como mencionado na seção anterior, não nos preocuparemos com as questões periféricas que não têm uma influência direta sobre o propósito do trabalho. Sendo assim, não definiremos neste momento o formato da saída do nosso projeto. Assim como a escolha da plataforma de virtualização não será feita neste momento, pois se faz necessário alguns testes para avaliação. Basta, entretanto afirmar que o projeto será executado com o auxílio de uma plataforma de nuvem que forneça uma API para coleta dos dados de utilização das VMs, mais especificamente os dados de processamento. E priorizaremos na escolha a API com um bom desempenho neste processo.

Em termos gerais a arquitetura do projeto contará com cinco módulos:

\begin{itemize}
	\item Módulo de captura, responsável pela comunicação com a ferramenta que fornecerá os dados de utilização da VM. Trata-se de um módulo relativamente simples, o qual tem como objetivo somente a comunicação com o sistema terceiro e a formatação dos dados para que sejam utilizados pelo sistema de predição.
	\item Módulo de tratamento dos dados que se destina a preparar as informações coletadas, para que sejam submetidas aos algoritmos de predição que serão testados. Dentre os procedimentos que serão desenvolvidos por este módulo estarão testes de validação, para garantir que a série seja adequada para os algoritmos aos quais será submetida. Também um tratamento para outliers será utilizado, com o intuito de evitar discrepâncias nas predições em decorrência da existência de valores atípicos na série examinada.
	\item Módulo de modelos probabilísticos, o qual provê a implementação de alguns dos algoritmos que iremos examinar. Este módulo recebe como entrada a série tratada e a submete aos modelos disponíveis, tendo como saída o resultado de suas previsões. A quantidade de modelos implementados irá depender de nossos testes de exatidão.
	\item Módulo de avaliação de precisão que objetiva analisar as previsões a partir de um indicador de aderência de previsão. E então escolher aquele que melhor modela o comportamento da aplicação submetida à análise.
	\item Módulo de exportação o qual é a última camada da aplicação, destinado a preparar os dados para a saída. É um módulo simples, com o intuito de definir um formato de apresentação para os dados da série de previsão.
\end{itemize}

\section{Metodologia de Avaliação}
O processo de avaliação se dará em dois momentos: a avaliação dos resultados de previsão por indicadores e a avaliação da aplicação frente aos objetivos a que o projeto se propôs. Teremos uma avaliação em tempo de execução através do \textit{módulo de avaliação de precisão}, descrito na seção anterior. Neste ponto nos utilizaremos de um indicador de aderência de previsão. O indicador escolhido será o \textit{Theil's U}, que é uma medida relativa a precisão que compara os resultados previstos com os dados históricos mínimos, analisando a aderência dos valores da previsão aos da tendência da série. Este índice também auxilia na eliminação de métodos que apresentem grandes erros \cite{Shumway2000}. Ele funcionará como um indicador constante de qualidade, avaliando em tempo real a exatidão das previsões, e portanto, podendo adaptá-las no caso de haver necessidade de fazê-lo. Além desta avaliação também utilizaremos a média de erro absoluto percentual (\textit{MAPE}), que também é conhecido como média de desvio percentual absoluto. É uma medida da precisão de um método para o cálculo dos valores de séries temporais, também relacionado à análise de tendência, e é geralmente expresso como uma percentagem de precisão.

O segundo momento de avaliação se refere a avaliação do modelo frente aos objetivos do projeto. Tendo em vista que buscamos um alto grau de exatidão das previsões, juntamente com um tempo de execução que não acrescente overhead significativo, a avaliação da aderência do modelo à sua proposta se utilizará dos indicadores descritos no parágrafo anterior, e dos tempos de processamento de diferentes amostras de carga (\textit{workload}) de dados da VM. Em termos gerais, o tempo de processamento e resposta do módulo de previsão não pode ser superior a janela de tempo necessária para implementar as mudanças sugeridas por ele. A resposta deve ser fornecida antes do período em que as mudanças devem ser aplicadas.



%=======================================================================
% CONCLUSÃO
%=======================================================================
\chapter{Conclusão}
TBD
\section{Cronograma}
Abaixo encontramos uma tabela com a relação de atividades previstas para o desenvolvimento deste trabalho, com um planejamento das suas respectivas datas de execução.

\begin{tabular}{|l|c|c|c|c|c|c|}\hline
 & \multicolumn{6}{c|}{\textbf{Meses}}\\ \cline{2-7}
\raisebox{1.5ex}{\textbf{Etapa}} & 01 & 02 & 03 & 04 & 05 & 06 										\\ \hline

Estudo e escolha da plataforma de cloud computing 						& X &   &   &   &   &		  	\\ \hline
Estudo e preparação do ambiente de execução de testes            		& X &   &   &   &   & 			\\ \hline
Modelagem da solução			 										& X & X &   &   &   &			\\ \hline
Definir estratégia para comparação de resultados						&   & X &   &   &   & 			\\ \hline
Desenvolvimento da extensão de balanceamento de carga					& 	& X &	&   &   &			\\ \hline
Testes e avaliação do balanceamento de carga							& 	& X & 	& 	& 	&  		   \\ \hline
Escrita do artigo														& X	& X & X & X & X & X			\\ \hline
Preparação da apresentação												& 	&   &   &   & X & X			\\ \hline
Baterias de testes para validação 										& 	& 	& 	& 	& 	& X 	   \\ \hline
Avaliação e tratamento dos resultados									& 	& 	& 	& 	& 	& X 	   \\ \hline

\end{tabular} 

\label{t_cronograma}

%=======================================================================
% Referências
%=======================================================================
\bibliography{exemplo}

%=======================================================================
% Exemplo de Apêndice
% O Apêndice é utilizado para apresentar material complementar elaborado
% pelo próprio autor.  Deve seguir as mesmas regras de formatação do
% corpo principal do documento.
%=======================================================================
\appendix
\chapter{Informações Complementares}

O Apêndice é o lugar para incluir textos complementares, que não são essenciais para o entendimento do assunto principal da monografia, mas que podem contribuir com informação relevante (por exemplo, uma prova matemática, uma conceituação básica, etc.).  Ele deve seguir o formato normal do documento.

%=======================================================================
% Exemplo de Anexo
% O Anexo é utilizado para a ``inclusão de materiais não elaborados pelo
% próprio autor, como cópias de artigos, manuais, folders, balancetes, etc.
% e não precisam estar em conformidade com o modelo''.
%=======================================================================
\annex
\chapter{Artigos Publicados}
Existe diferença entre os Apêndices e os Anexos.  Os apêndices trazem informação escrita pelo próprio autor do trabalho, incorporando-se ao formato da monografia como um todo.  Já um anexo é um material à parte, definido/publicado por si só, e que o autor julga conveniente ser apresentado juntamente com a monografia.  Normalmente também vai apresentar formato próprio, como um artigo publicado, um folder, uma planilha, etc.
\end{document}
